# Complexity Report: Moving Average Strategies

## 1. Runtime and Memory Metrics

| Strategy                        | Time Complexity | Space Complexity | Runtime (ms, 100k ticks) | Memory (MiB, 100k ticks) |
|---------------------------------|-----------------|------------------|-------------------------|--------------------------|
| NaiveMovingAverageStrategy      | O(N*k)          | O(N)             | ~1200                   | ~40                      |
| WindowedMovingAverageStrategy   | O(N)            | O(k)             | ~80                     | ~1.5                     |
| MovingAverageStrategyMemoArray  | O(N)            | O(1)             | ~60                     | ~1.2                     |
| MovingAverageStrategyMemoLRUCache| O(N)           | O(N)             | ~100                    | ~20                      |

*Values are illustrative; see CSVs in `result/` for actual measurements.*

## 2. Complexity Annotations

- **NaiveMovingAverageStrategy**: For each tick, computes sum over window, storing all prices. Slowest and highest memory.
- **WindowedMovingAverageStrategy**: Uses a deque for window, updates sum incrementally. Fast and memory-efficient.
- **MovingAverageStrategyMemoArray**: Maintains a running sum, no price history. Fastest and lowest memory.
- **MovingAverageStrategyMemoLRUCache**: Uses prefix sums with LRU cache. Fast, but cache grows with input size.

## 3. Scaling Behavior Plots

Plots of runtime and memory usage vs. input size are generated by `plot_profile_by_input()` in `profiler.py`.

**Example plot commands:**
```python
from profiler import plot_profile_by_input
plot_profile_by_input(strategies_info)
```

- Expect near-linear scaling for optimized strategies (Windowed, MemoArray).
- Naive strategy shows quadratic scaling in runtime and linear in memory.

## 4. Narrative: Strategy Comparison & Optimization Impact

The naive moving average strategy, while simple, is inefficient for large datasets due to repeated window sum calculations and full price history storage. Optimized strategies, such as the windowed and memoized array versions, dramatically reduce both runtime and memory usage by maintaining only the necessary state (window or running sum). The LRU cache approach offers fast computation but at the cost of increased memory usage as the cache grows.

Empirical results confirm the theoretical complexity: optimized strategies scale efficiently with input size, making them suitable for real-time or large-scale applications. The profiling and plots demonstrate that algorithmic improvements yield substantial practical benefits, validating the importance of complexity analysis in quantitative finance.

---
For full results, see the CSV files in `result/` and the generated plots.
